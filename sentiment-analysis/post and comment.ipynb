{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creates the DataFrame from data_relevance_training.csv and extracts the two needed columns.\n",
    "Then, manipulates the string content in the specified way before saving as df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>relevance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Coolest President Heart Suit Green Heart V...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>After YRS Sandro will be the next president sm...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>God bless you always sir pbbm red heart red he...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I was in tears of sincerity and inday sarah ho...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Good news you loyalist negative BBM's result i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  relevance\n",
       "0  The Coolest President Heart Suit Green Heart V...          0\n",
       "1  After YRS Sandro will be the next president sm...          1\n",
       "2  God bless you always sir pbbm red heart red he...          1\n",
       "3  I was in tears of sincerity and inday sarah ho...          1\n",
       "4  Good news you loyalist negative BBM's result i...          1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ENCODING = {'irrelevant': 0, 'relevant': 1}\n",
    "\n",
    "data: pd.DataFrame = pd.read_csv('../data/labeled/cleaned/combined/data_relevance_training.csv')\n",
    "encoded: pd.Series = data['relevance'].apply(lambda x: ENCODING[x])\n",
    "\n",
    "# Splits on the separator ' .' and rejoins the post with its comment.\n",
    "text: pd.Series = data['text'].apply(lambda x: ''.join(x.split(' .')))\n",
    "df = pd.DataFrame([text, encoded]).T\n",
    "df = df.astype({'text': 'string', 'relevance': 'int'})\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vectorizes the text using sklearn Tfidfvectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 1605)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_df=0.95, lowercase=True)\n",
    "tf_idf = vectorizer.fit_transform(df['text'])\n",
    "words = vectorizer.get_feature_names_out()\n",
    "tf_idf = normalize(tf_idf).toarray()\n",
    "tf_idf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does an 80-20 train-test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(tf_idf, df.relevance, test_size= .2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generates all the classifier models to be tested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "svc = SVC(kernel='sigmoid', gamma=1.0)\n",
    "knc = KNeighborsClassifier(n_neighbors=5)\n",
    "mnb = MultinomialNB(alpha=0.2)\n",
    "dtc = DecisionTreeClassifier(min_samples_split=2)\n",
    "lrc = LogisticRegression(solver='liblinear', penalty='l1')\n",
    "rfc = RandomForestClassifier(n_estimators=31)\n",
    "ada = AdaBoostClassifier()\n",
    "mlp = MLPClassifier()\n",
    "\n",
    "classifiers = {'SVC': svc, \n",
    "               'KNeighborsClassifier': knc,\n",
    "               'Multinomial Naive Bayes': mnb,\n",
    "               'Decision Tree': dtc,\n",
    "               'Logistic Regression': lrc,\n",
    "               'Random Forest': rfc,\n",
    "               'AdaBoost': ada,\n",
    "               'Multi-Layer Perceptron': mlp}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fits and subsequently evaluates the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marko\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\marko\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\marko\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\marko\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\marko\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\marko\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train_scores = []\n",
    "for name, model in classifiers.items():\n",
    "    model.fit(x_train, y_train)\n",
    "    y_pred = model.predict(x_test)\n",
    "    train_scores.append((name, accuracy_score(y_test , y_pred)))\n",
    "    \n",
    "crossval_scores = []\n",
    "for name, model in classifiers.items():\n",
    "    scores = cross_val_score(model, x_test, y_test, cv=5)\n",
    "    crossval_scores.append((name, scores.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prints the resultant scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Training Scores\n",
      "SVC: 0.77\n",
      "KNeighborsClassifier: 0.67\n",
      "Multinomial Naive Bayes: 0.78\n",
      "Decision Tree: 0.74\n",
      "Logistic Regression: 0.78\n",
      "Random Forest: 0.74\n",
      "AdaBoost: 0.77\n",
      "Multi-Layer Perceptron: 0.77\n",
      "\n",
      "Cross-Validation Scores\n",
      "SVC: 0.7200000000000001\n",
      "KNeighborsClassifier: 0.63\n",
      "Multinomial Naive Bayes: 0.7100000000000002\n",
      "Decision Tree: 0.7300000000000001\n",
      "Logistic Regression: 0.55\n",
      "Random Forest: 0.65\n",
      "AdaBoost: 0.71\n",
      "Multi-Layer Perceptron: 0.7300000000000001\n"
     ]
    }
   ],
   "source": [
    "print('Model Training Scores')\n",
    "for item in train_scores:\n",
    "    print(f'{item[0]}: {item[1]}')\n",
    "    \n",
    "print('\\nCross-Validation Scores')\n",
    "for item in crossval_scores:\n",
    "    print(f'{item[0]}: {item[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tests them on the four quotes from the English Reference Approach Jupyter notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Imagine if late president ferdinand marcos sr was still alive and witnessed this glorious moment sneezing that's the president of the mass sweet and cute dad solid bbm smiling with hearts smiling with hearts smiling with hearts\"\n",
      "\tSVC: Relevant\n",
      "\tKNeighborsClassifier: Relevant\n",
      "\tMultinomial Naive Bayes: Relevant\n",
      "\tDecision Tree: Relevant\n",
      "\tLogistic Regression: Relevant\n",
      "\tRandom Forest: Relevant\n",
      "\tAdaBoost: Relevant\n",
      "\tMulti-Layer Perceptron: Relevant\n",
      "\n",
      "\"Long live APO UN PBBM Red Heart Red Heart The AFTR shocks are still on the ABRA POEPICENTER STAYSAFE FOLDED HANDS FOLDED HANDS Bangonabrenios Red Heart\"\n",
      "\tSVC: Relevant\n",
      "\tKNeighborsClassifier: Relevant\n",
      "\tMultinomial Naive Bayes: Relevant\n",
      "\tDecision Tree: Relevant\n",
      "\tLogistic Regression: Relevant\n",
      "\tRandom Forest: Relevant\n",
      "\tAdaBoost: Relevant\n",
      "\tMulti-Layer Perceptron: Relevant\n",
      "\n",
      "\"The amount of appreciation gratitude and respect he has for the frontliners Don't Irene Marcos unn seconds turned shade\"\n",
      "\tSVC: Irrelevant\n",
      "\tKNeighborsClassifier: Irrelevant\n",
      "\tMultinomial Naive Bayes: Irrelevant\n",
      "\tDecision Tree: Relevant\n",
      "\tLogistic Regression: Irrelevant\n",
      "\tRandom Forest: Relevant\n",
      "\tAdaBoost: Relevant\n",
      "\tMulti-Layer Perceptron: Relevant\n",
      "\n",
      "\"random word\"\n",
      "\tSVC: Irrelevant\n",
      "\tKNeighborsClassifier: Relevant\n",
      "\tMultinomial Naive Bayes: Relevant\n",
      "\tDecision Tree: Irrelevant\n",
      "\tLogistic Regression: Irrelevant\n",
      "\tRandom Forest: Irrelevant\n",
      "\tAdaBoost: Irrelevant\n",
      "\tMulti-Layer Perceptron: Relevant\n",
      "\n"
     ]
    }
   ],
   "source": [
    "TEXT = [[\"Imagine if late president ferdinand marcos sr was still alive and witnessed this glorious moment sneezing that's the president of the mass sweet and cute dad solid bbm smiling with hearts smiling with hearts smiling with hearts\"],\n",
    "        [\"Long live APO UN PBBM Red Heart Red Heart The AFTR shocks are still on the ABRA POEPICENTER STAYSAFE FOLDED HANDS FOLDED HANDS Bangonabrenios Red Heart\"],\n",
    "        [\"The amount of appreciation gratitude and respect he has for the frontliners Don't Irene Marcos unn seconds turned shade\"],\n",
    "        [\"random word\"]]\n",
    "\n",
    "DECODING = ['Irrelevant', 'Relevant']\n",
    "\n",
    "for tweet in TEXT:\n",
    "    tweettfidf = vectorizer.transform(tweet).toarray()\n",
    "    print(f'\"{tweet[0]}\"')\n",
    "    for name, model in classifiers.items():\n",
    "        print(f'\\t{name}: {DECODING[model.predict(tweettfidf)[0]]}')\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "63ff4dc2dd031f4852d607fdb3ec67fe08a87deee7c75aae11edc48254a35360"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
